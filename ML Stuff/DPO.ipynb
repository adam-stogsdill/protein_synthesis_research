{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def dpo_loss(pi_logps, ref_logps, yw_idxs, yl_idxs, beta):\n",
    "    \"\"\"\n",
    "    pi_logps: policy logprobs, shape (B,)\n",
    "    ref_logps: reference model logprobs, shape (B,)\n",
    "    yw_idxs: preferred completion indices in [0, B-1], shape (T,)\n",
    "    yl_idxs: dispreferred completion indices in [0, B-1], shape (T,)\n",
    "    beta: temperature controlling strength of KL penalty\n",
    "    \"\"\"\n",
    "    pi_yw_logps, pi_yl_logps = pi_logps[yw_idxs], pi_logps[yl_idxs]\n",
    "    ref_yw_logps, ref_yl_logps = ref_logps[yw_idxs], ref_logps[yl_idxs]\n",
    "    pi_logratios = pi_yw_logps - pi_yl_logps\n",
    "    ref_logratios = ref_yw_logps - ref_yl_logps\n",
    "    losses = -F.logsigmoid(beta * (pi_logratios - ref_logratios))\n",
    "    return losses\n",
    "\n",
    "def dpo_loss_single(pi_logps, ref_logps, beta):\n",
    "    \"\"\"\n",
    "    pi_logps: policy logprobs, shape (B,)\n",
    "    ref_logps: reference model logprobs, shape (B,)\n",
    "    yw_idxs: preferred completion indices in [0, B-1], shape (T,)\n",
    "    yl_idxs: dispreferred completion indices in [0, B-1], shape (T,)\n",
    "    beta: temperature controlling strength of KL penalty\n",
    "    \"\"\"\n",
    "    pi_yw_logps, pi_yl_logps = pi_logps, pi_logps\n",
    "    ref_yw_logps, ref_yl_logps = ref_logps, ref_logps\n",
    "    pi_logratios = pi_yw_logps - pi_yl_logps\n",
    "    ref_logratios = ref_yw_logps - ref_yl_logps\n",
    "    losses = -F.logsigmoid(beta * (pi_logratios - ref_logratios))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\miniconda3\\envs\\'work_env'\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# my own code\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "fine_tuning_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "reference_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets go ahead and freeze the weights of our reference model\n",
    "for param in reference_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make some example data\n",
    "# make the batch size 2\n",
    "prompts = [\n",
    "    'Hello my name is',\n",
    "    'The wheather is quite',\n",
    "    \"This sentence is going\"\n",
    "]\n",
    "\n",
    "preffered_response = [\n",
    "    'Adam',\n",
    "    'humid',\n",
    "    'to be really long'\n",
    "]\n",
    "\n",
    "rejected_response = [\n",
    "    'Arnold',\n",
    "    'sunny',\n",
    "    'to be short'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_lengths = [tokenizer(prompt, return_tensors='pt')['input_ids'].shape[-1] for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets combine the prompts and the answer.\n",
    "prompts_preferred = [prompt + ' ' + pr for prompt, pr in zip(prompts, preffered_response)]\n",
    "prompts_rejected = [prompt + ' ' + rj for prompt, rj in zip(prompts, rejected_response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello my name is Adam',\n",
       " 'The wheather is quite humid',\n",
       " 'This sentence is going to be really long']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can tokenize each one\n",
    "tokenized_pp = [tokenizer(pp, return_tensors='pt') for pp in prompts_preferred]\n",
    "tokenized_pr = [tokenizer(pr, return_tensors='pt') for pr in prompts_rejected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[15496,   616,  1438,   318,  7244]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[  464,   483,  1032,   318,  2407, 35441]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[1212, 6827,  318, 1016,  284,  307, 1107,  890]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log probabilities\n",
    "logits_pp = [fine_tuning_model(**pp).logits for pp in tokenized_pp]\n",
    "logits_pr = [fine_tuning_model(**pr).logits for pr in tokenized_pr]\n",
    "ref_logits_pp = [reference_model(**pp).logits for pp in tokenized_pp]\n",
    "ref_logits_pr = [reference_model(**pr).logits for pr in tokenized_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log probabilities\n",
    "lgpr_pp = [torch.nn.functional.log_softmax(pp, dim=-1) for pp in logits_pp]\n",
    "lgpr_pr = [torch.nn.functional.log_softmax(pr, dim=-1) for pr in logits_pr]\n",
    "ref_lgpr_pp = [torch.nn.functional.log_softmax(pp, dim=-1) for pp in ref_logits_pp]\n",
    "ref_lgpr_pr = [torch.nn.functional.log_softmax(pr, dim=-1) for pr in ref_logits_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgpr_pp_sums = []\n",
    "lgpr_pr_sums = []\n",
    "ref_lgpr_pp_sums = []\n",
    "ref_lgpr_pr_sums = []\n",
    "for i in range(len(lgpr_pp)):\n",
    "    lgpr_pp_sums.append(torch.sum(torch.gather(lgpr_pp[i][:, prompts_lengths[i]-1:, :], dim=2, index=tokenizer(\" \" + preffered_response[i], return_tensors='pt')['input_ids'].unsqueeze(2)).squeeze(2)))\n",
    "    lgpr_pr_sums.append(torch.sum(torch.gather(lgpr_pr[i][:, prompts_lengths[i]-1:, :], dim=2, index=tokenizer(\" \" + rejected_response[i], return_tensors='pt')['input_ids'].unsqueeze(2)).squeeze(2)))\n",
    "    ref_lgpr_pp_sums.append(torch.sum(torch.gather(lgpr_pp[i][:, prompts_lengths[i]-1:, :], dim=2, index=tokenizer(\" \" + preffered_response[i], return_tensors='pt')['input_ids'].unsqueeze(2)).squeeze(2)))\n",
    "    ref_lgpr_pr_sums.append(torch.sum(torch.gather(lgpr_pr[i][:, prompts_lengths[i]-1:, :], dim=2, index=tokenizer(\" \" + rejected_response[i], return_tensors='pt')['input_ids'].unsqueeze(2)).squeeze(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0769, -1.2717, -5.1082, -3.6530]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(lgpr_pp[-1][:, prompts_lengths[-1]-1:, :], dim=2, index=tokenizer(\" \" + preffered_response[-1], return_tensors='pt')['input_ids'].unsqueeze(2)).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-7.9237, grad_fn=<SumBackward0>),\n",
       " tensor(-11.0358, grad_fn=<SumBackward0>),\n",
       " tensor(-8.0154, grad_fn=<SumBackward0>)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgpr_pr_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
